---
layout: homepage
---
&#x2665; [Education](#education)  &nbsp;｜ [News](#news)  &nbsp;｜ [Products](#aiviz) &nbsp;｜ [Publicaitons](#publications) &nbsp;｜ [Teaching](#teaching) &nbsp;｜ [Life Cakes](#life)

## <span id='about'>About Me</span>
<p align="justify">
Hello! My name is <font size=4px>Xiaoqin Feng</font>. 
I am a Master’s student at the University of Southern California (USC) with research interests in Generative AI, LLM-powered agents, Human-AI Collaboration, and AI for Science. My work emphasizes agents, speech, data, evaluation, and real-world applications. I bring hands-on industry experience in these areas and am dedicated to advancing artificial intelligence through rigorous research and practical innovation.</p>
<p style="border-left:4px solid #e67e22; background:#fff8f1; padding:10px 12px; border-radius:8px; margin:10px 0 18px;">
Here is my <a href="https://xqfeng-josie.github.io/resume/xiaoqin_cv.pdf" style="color:#c0392b; font-weight:600;">CV</a>. I am actively seeking <strong style="color:#c0392b;">PhD programs starting in 2027</strong> and <strong style="color:#c0392b;">2026 Summer Internships</strong> (SDE/ML/AI Engineering, etc.)—feel free to email me if you're interested.
</p>
<!-- **<font color=red>&#x1F4EC;I am applying for M.S. or MBA in computer science. </font>**Here is my [CV](https://xqfeng-josie.github.io/resume/xiaoqin_cv.pdf) and my [personal research statement](https://xqfeng-josie.github.io/resume/PS/xiaoqin-ps-general.pdf). -->

<div id="aiviz" style="border:2px solid #e67e22; background:#fff8f1; border-radius:12px; padding:18px 20px 16px; margin:16px 0 28px; box-shadow:0 10px 24px rgba(0,0,0,0.06);">
<h2 style="margin-top:4px; margin-bottom:14px; color:#c0392b;">AI Products</h2>
<p align="justify" style="margin-bottom:12px;">
I am building a next-generation AI audio visualization experience that blends speech intelligence with interactive visuals. You can try the latest demo and share feedback to shape where it goes next.
</p>
<ul style="margin:0 0 4px 18px;">
  <li>Live demo: <a href="https://qinzhi-a56d5.web.app/" style="color:#c0392b; font-weight:600;">qinzhi-a56d5.web.app</a></li>
  <li>Looking for collaborators, beta users, or partners—please reach out if this resonates with you.</li>
</ul>
</div>

<!-- ## <span id='interests'>Research Interests</span>   

- **Natural Language Processing:** natural language understanding, semantic analysis, knowledge acquisition, 
information extraction, information representation, and their practical application. 
- **Machine Learning:** robust learning, unsupervised learning or semi-supervised learning, transfer learning.
- **Data Science:** data mining, dataset construction. -->
<!--
<strong style="color:#e74d3c; font-weight:600">I am looking for a postdoc or research scientist position in the US and EU. I would appreciate a ping if you see a job I might fit.</strong>
-->

## <span id='education'>Education</span>   
- **[Sep. 2025 –  Present]** M.S in Artificial Intelligence at [University of Southern California(USC)](https://english.bjut.edu.cn/)
- **[Sep. 2016 –  May. 2019]** M.S  in Software Engineer at [Beijing University of Technology(BJUT)](https://english.bjut.edu.cn/), overall grade: 86 (max. 100) between “Very Good” and “Good”
- **[Sep. 2012 – May. 2016]** B.S. in Computer Science at [Southwest Minzu University(SMU)](https://english.swun.edu.cn/), overall grade: 3.66 (max. 4.0), “Top 5” of 154 students

## <span id='activity'>Employment and Activity</span>   
- **[Aug. 2025 - Present]** [Mobvoi AI Lab](https://www.mobvoi.com/us), Part-time Consultant. Support product decision-making by focusing on model optimization, multi-agent systems, and real-time information tracking.
- **[May. 2023 - Jul. 2025]** [Mobvoi AI Lab](https://www.mobvoi.com/us), Tech Lead. Research on LLM agent, LLM application, Audio LLM, prompt engineering, data engineering and model evaluation. (Agent & Application & Data& Evaluation)
- **[Jul. 2019 - May. 2023]** [Mobvoi AI Lab](https://www.mobvoi.com/us), Senior Speech Engineer. Research on speech synthesis on multi- and cross- lingual domain, including semantic NLP, emotional NLP and generative NLP.
- **[Aug. 2018 - Dec. 2018]** [TAL AI Lab](https://en.100tal.com/), Algorithm Research Intern. Research on deep knowledge tracing and graph representation learning.
- **[Jun. 2018 - Aug. 2018]** [DeeCamp AI Lab](https://deecamp.com/#/home), Research Team Member. Research on ‘Movie Recommendation based on Knowledge Graph’. [github](https://github.com/XqFeng-Josie/Recommender-System-RS/tree/master/deecamp2018)
- **[Sep. 2017 – Dec. 2017]** [Ali Tianchi Competition](https://tianchi.aliyun.com/competition/entrance/231620/information), Competitor. Topic was predicting user’s current store location based on user consumption data(one million+). Research on linear model, emsemble model, and big data mining.
- waiting to be added .....

## <span id='news'>News</span>  
- **[Dec. 2025]** Launched an interactive AI audio visualization web—try it here: [qinzhi-a56d5.web.app](https://qinzhi-a56d5.web.app/).
- **[Oct. 2024]** Our paper about Audio LLM - SparkTTS is available on arXiv 2025.
- **[Oct. 2023]** Our paper about information extraction and Multilingual has been accepted by APIN(Applied Intelligence) 2024.
- **[Oct. 2022]** Our paper about multi-granularity stress prediction of expressive TTS has been accepted by APSIPA 2023.
- **[Jul. 2022]** Our paper about prompt learning(rhythm) has been accepted by PRML 2022.
- **[Jun. 2019]** Our paper about knowledge tracing has been accepted by AIED 2019.
- **[Jun. 2019]** Our paper about image detection has been accepted by Journal of Physics 2019
- **[Oct. 2018]** Our paper about quick edge detection(image) has been accepted by CCIOT 2018.
- **[Nov. 2018]** Our paper about cloud computing and intelligence system has been accepted by CCIS 2018.

<h2 id="publications" style="margin: 2px 0px -15px;"><span id='publications'>Publications</span><temp style="font-size:15px;">[</temp><a href="https://scholar.google.com/citations?user=-rW26N0AAAAJ" target="_blank" style="font-size:15px;">Google Scholar</a><temp style="font-size:15px;">]</temp></h2>

<div class="publications">
<ol class="bibliography">




<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="/assets/img/SparkTTS.jpg" class="teaser img-fluid z-depth-1">
            <abbr class="badge">SparkTTS</abbr>
  </div>
  <div id="peng2021copo" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
      <div class="title"> <a href="https://arxiv.org/pdf/2503.01710"> Spark-TTS: An Efficient LLM-Based Text-to-Speech Model with
Single-Stream Decoupled Speech Tokens </a></div>
      <div class="author">
        Xinsheng Wang, <strong><u>Xiaoqin Feng</u></strong>,et al.
      </div>
      <div class="periodical"><em>arXiv preprint 2025, 22 pages</em>
      </div>
    <div class="links">
      <a href="https://arxiv.org/pdf/2503.01710" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <!-- <a href="https://github.com/yaoyao-liu/meta-transfer-learning" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://bibliography.yliu.de/TPAMI22.txt" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">BibTex</a> -->
    </div>
  </div>
</div>
</li>


<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="/assets/img/APIN_2024.jpg" class="teaser img-fluid z-depth-1">
            <abbr class="badge">APIN</abbr>
  </div>
  <div id="peng2021copo" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
      <div class="title"> <a href="https://arxiv.org/pdf/2404.17122v1"> 2M-NER: Contrastive Learning for Multilingual and Multimodal NER with Language and Modal Fusion </a></div>
      <div class="author">
        Dongsheng Wang, <strong><u>Xiaoqin Feng</u></strong>,et al.
      </div>
      <div class="periodical"><em>In proceedings of Applied Intelligence 2024, 20 pages</em>
      </div>
    <div class="links">
      <a href="https://arxiv.org/pdf/2404.17122v1" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <!-- <a href="https://github.com/yaoyao-liu/meta-transfer-learning" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://bibliography.yliu.de/TPAMI22.txt" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">BibTex</a> -->
    </div>
  </div>
</div>
</li>


<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="/assets/img/APSIPA2023.png" class="teaser img-fluid z-depth-1">
            <abbr class="badge">APSIPA</abbr>
  </div>
  <div id="peng2021copo" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
      <div class="title"><a href="https://xqfeng-josie.github.io/resume/publications/APSIPA2023.pdf">Multi-granularity Semantic and Acoustic Stress Prediction for Expressive TTS </a></div>
      <div class="author">
        Wenjiang Chi, <strong><u>Xiaoqin Feng(*euqal contribution)</u></strong>,et al.
      </div>
      <div class="periodical"><em>In proceedings of APSIPA 2023, 5 pages</em>
      </div>
    <div class="links">
      <a href="https://xqfeng-josie.github.io/resume/publications/APSIPA2023.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <a href="https://xqfeng-josie.github.io/stress/" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Demo</a>
      <!-- <a href="https://github.com/yaoyao-liu/meta-transfer-learning" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://bibliography.yliu.de/TPAMI22.txt" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">BibTex</a> -->
    </div>
  </div>
</div>
</li>



<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="/assets/img/prompt2022.png" class="teaser img-fluid z-depth-1">
            <abbr class="badge">PRML</abbr>
  </div>
  <div id="peng2021copo" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
      <div class="title"><a href="https://xqfeng-josie.github.io/resume/publications/PRML2022.pdf">Prosody Prediction with Discriminative Representation Method</a></div>
      <div class="author">
        Jipeng Zhang, Hankiz Yilahun, <strong><u>Xiaoqin Feng</u></strong>, Yunlin Chen, Xipeng Yang, Askar Hamdulla
      </div>
      <div class="periodical"><em>In proceedings of PRML 2022, 5 pages</em>
      </div>
    <div class="links">
    <a href="https://xqfeng-josie.github.io/resume/publications/PRML2022.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <!-- <a href="https://ieeexplore.ieee.org/abstract/document/9882251" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a> -->
      <!-- <a href="https://github.com/yaoyao-liu/meta-transfer-learning" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://bibliography.yliu.de/TPAMI22.txt" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">BibTex</a> -->
    </div>
  </div>
</div>
</li>

<br>
  
<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="/assets/img/knowledge2019.png" class="teaser img-fluid z-depth-1">
            <abbr class="badge">AIED</abbr>
  </div>
  <div id="peng2021copo" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
      <div class="title"><a href="https://arxiv.org/pdf/1909.00372.pdf">Deep knowledge tracing with side information</a></div>
      <div class="author">
        Zhiwei Wang, <strong><u>Xiaoqin Feng</u></strong>, Jiliang Tang, Gale Yan Huang, Zitao Liu</div>
      <div class="periodical"><em>In proceedings of AIED 2019, Springer, Cham, 5 pages</em>
      </div>
    <div class="links">
      <a href="https://arxiv.org/pdf/1909.00372.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <!-- <a href="https://gitlab.mpi-klsb.mpg.de/yaoyaoliu/rmm/" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://class-il.mpi-inf.mpg.de/rmm/" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Project Page</a>
      <a href="https://bibliography.yliu.de/NeurIPS21.txt" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">BibTex</a> -->
    </div>
  </div>
</div>
</li>
<br>


<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="/assets/img/mobilenet2018.png" class="teaser img-fluid z-depth-1">
            <abbr class="badge">Journal of Physics</abbr>
  </div>
  <div id="peng2021copo" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
      <div class="title"><a href="https://iopscience.iop.org/article/10.1088/1742-6596/1237/2/022045/pdf">Population statistics algorithm based on MobileNet</a></div>
      <div class="author"><strong><u>Xiaoqin Feng</u></strong>, Rong Xie, Junyang Sheng, Shuo Zhang</div>
      <div class="periodical"><em>Journal of Physics: Conference Series. JPCS 2019, 6 pages</em>
      </div>
    <div class="links">
      <a href="https://iopscience.iop.org/article/10.1088/1742-6596/1237/2/022045/pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <!-- <a href="https://github.com/xinzheli1217/learning-to-self-train" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://bibliography.yliu.de/CVIU21.txt" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">BibTex</a> -->
    </div>
  </div>
</div>
</li>
<br>
<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="/assets/img/imagedetect2018.png" class="teaser img-fluid z-depth-1">
            <abbr class="badge">CCIOT</abbr>
  </div>
  <div id="peng2021copo" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
      <div class="title"><a href="https://xqfeng-josie.github.io/resume/publications/CCIOT2018.pdf">A method of quick edge detection based on Zynq</a></div>
      <div class="author">  Rong Xie, <strong><u>Xiaoqin Feng</u></strong></div>
      <div class="periodical"><em> In proceedings of CCIOT 2018, 5 pages.</em>
      </div>
    <div class="links">
     <a href="https://xqfeng-josie.github.io/resume/publications/CCIOT2018.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
<!-- 
      <a href="https://ieeexplore.ieee.org/document/9032641" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a> -->
      <!-- <a href="https://github.com/xinzheli1217/learning-to-self-train" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://bibliography.yliu.de/CVIU21.txt" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">BibTex</a> -->
    </div>
  </div>
</div>
</li>

<br>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="/assets/img/ccis2018.png" class="teaser img-fluid z-depth-1">
            <abbr class="badge">CCIS</abbr>
  </div>
  <div id="peng2021copo" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
      <div class="title"><a href="https://xqfeng-josie.github.io/resume/publications/CCIS2018.pdf">Research on the Internet of Things Platform for Smart and Environmental Protection</a></div>
      <div class="author"> Junyang Sheng, <strong><u>Xiaoqin Feng</u></strong></div>
      <div class="periodical"><em>In proceedings of CCIS 2018, 5 pages</em>
      </div>
    <div class="links">
     <a href="https://xqfeng-josie.github.io/resume/publications/CCIS2018.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>

      <!-- <a href="https://ieeexplore.ieee.org/document/8691352" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a> -->
      <!-- <a href="https://dblp.uni-trier.de/rec/journals/tnn/LiuSHLSC21.html?view=bibtex" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">BibTex</a> -->
    </div>
  </div>
</div>
</li>

<br>
  

</ol>
</div>

## <span id='teaching'>Teaching</span>

- Lecture - Embedded System Design Practice <br>As teaching assistant at BJUT, for M.Sc. students, approx. 80 students each year. Winter 2018

- Company - Speech & NLP <br>As a mentor at Mobvoi, for interns (students), avg. 3 students each year. Annual  2021-Present

## <span id='life'>Life Cakes</span> 
- I love music, cooking, reading, traveling...
- Here is my life stroy, expecting .....